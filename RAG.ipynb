{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af44119d",
   "metadata": {},
   "source": [
    "Step 1: Imports and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72eaa2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\prmsr\\anaconda3\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\prmsr\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json, os, re, unicodedata, pathlib\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch, faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "KB_PATH   = \"knowledge_base.json\"  \n",
    "EMBED_MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "GEN_MODEL_NAME   = \"google/flan-t5-small\"\n",
    "\n",
    "INDEX_FILE = \"faiss.index\"\n",
    "EMB_FILE   = \"embeddings.npy\"\n",
    "\n",
    "TOP_K = 3                    # retrieved chunks\n",
    "DISTANCE_THRESHOLD = 1     # > threshold → “I don’t know”\n",
    "HISTORY_MAX = 3              # previous Q-A pairs fed back to model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1780c6",
   "metadata": {},
   "source": [
    "Step 2: Simple text cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c728707a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PUNCT_RE = re.compile(r\"[^\\w\\s]\")\n",
    "\n",
    "def clean(text: str) -> str:\n",
    "    if not text:\n",
    "        return \"\"\n",
    "    text = unicodedata.normalize(\"NFKD\", text)\n",
    "    text = text.encode(\"ascii\", \"ignore\").decode()  # drop non-ASCII remnants\n",
    "    text = text.lower()\n",
    "    text = PUNCT_RE.sub(\" \", text)\n",
    "    return re.sub(r\"\\s+\", \" \", text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c9d1f4",
   "metadata": {},
   "source": [
    "Step 3: Load the two models (MiniLM + Flan-T5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74be5adb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "embedder  = SentenceTransformer(EMBED_MODEL_NAME, device=DEVICE)\n",
    "tokenizer = AutoTokenizer.from_pretrained(GEN_MODEL_NAME)\n",
    "generator = AutoModelForSeq2SeqLM.from_pretrained(GEN_MODEL_NAME).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d62693",
   "metadata": {},
   "source": [
    "Step 4: Read the restaurants knowledge base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afdd19e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_kb(path: str) -> List[Dict]:\n",
    "    data = json.load(open(path, encoding=\"utf-8\"))\n",
    "    return list(data.values()) if isinstance(data, dict) else data\n",
    "\n",
    "restaurants = load_kb(KB_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c14cafa",
   "metadata": {},
   "source": [
    "Step 5: Flatten each menu item into an indexable text chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "705524ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prepared 292 chunks\n"
     ]
    }
   ],
   "source": [
    "texts, meta = [], []\n",
    "\n",
    "for r in restaurants:\n",
    "    rname, rloc = r[\"restaurant_name\"], r[\"location\"]\n",
    "    for it in r[\"items\"]:\n",
    "        txt_raw = (\n",
    "            f\"{rname} {rloc} {it['category']} \"\n",
    "            f\"{it['item_name']} {it['description']} \"\n",
    "            f\"{' '.join(it['special_features'] or [])}\"\n",
    "        )\n",
    "        texts.append(clean(txt_raw))\n",
    "        meta.append(\n",
    "            {\n",
    "                \"restaurant\": rname,\n",
    "                \"category\"  : it[\"category\"],\n",
    "                \"item_name\" : it[\"item_name\"],\n",
    "                \"url\"       : it[\"product_url\"],\n",
    "                \"price\"     : it[\"price\"],\n",
    "                \"features\"  : it[\"special_features\"],\n",
    "            }\n",
    "        )\n",
    "\n",
    "print(f\"Prepared {len(texts)} chunks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277cc4f6",
   "metadata": {},
   "source": [
    "Step 6: Build an FAISS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b9af71e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index size: 292\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(INDEX_FILE) and os.path.exists(EMB_FILE):\n",
    "    faiss_index = faiss.read_index(INDEX_FILE)\n",
    "else:\n",
    "    emb = embedder.encode(texts, batch_size=64, show_progress_bar=True,\n",
    "                          convert_to_numpy=True)\n",
    "    faiss_index = faiss.IndexFlatL2(emb.shape[1])\n",
    "    faiss_index.add(emb)\n",
    "    faiss.write_index(faiss_index, INDEX_FILE)\n",
    "    emb.tofile(EMB_FILE)\n",
    "\n",
    "print(\"Index size:\", faiss_index.ntotal)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fdc8181",
   "metadata": {},
   "source": [
    "Step 7: Top-k retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53675b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(query: str, k: int = TOP_K) -> List[Dict]:\n",
    "    q_emb = embedder.encode([clean(query)], convert_to_numpy=True)\n",
    "    dist, idx = faiss_index.search(q_emb, k)\n",
    "    return [\n",
    "        {\n",
    "            \"text\"    : texts[i],\n",
    "            \"meta\"    : meta[i],\n",
    "            \"distance\": float(dist[0][rank]),\n",
    "        }\n",
    "        for rank, i in enumerate(idx[0])\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84aa6fb5",
   "metadata": {},
   "source": [
    "Step 8: Minimal history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4b5bb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conversation:\n",
    "    def __init__(self, max_turns: int = HISTORY_MAX):\n",
    "        self.max = max_turns\n",
    "        self.memory: List[Tuple[str, str]] = []\n",
    "\n",
    "    def add(self, user: str, assistant: str) -> None:\n",
    "        self.memory.append((user, assistant))\n",
    "        if len(self.memory) > self.max:\n",
    "            self.memory.pop(0)\n",
    "\n",
    "    def format_history(self) -> str:\n",
    "        if not self.memory:\n",
    "            return \"\"\n",
    "        lines = [f\"User: {u}\\nAssistant: {a}\" for u, a in self.memory]\n",
    "        return \"\\n\".join(lines) + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737007cb",
   "metadata": {},
   "source": [
    "Step 9: Build prompt with context + history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf020c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM = (\n",
    "    \"You answer questions about restaurant menus using ONLY the CONTEXT. \"\n",
    "    \"If the answer cannot be found, say you do not know.\"\n",
    ")\n",
    "\n",
    "def make_prompt(query: str,\n",
    "                ctx_chunks: List[str],\n",
    "                history: str) -> str:\n",
    "    ctx = \"\\n\".join(ctx_chunks)\n",
    "    return (\n",
    "        f\"{SYSTEM}\\n\\n\"\n",
    "        f\"{history}\"\n",
    "        f\"CONTEXT:\\n{ctx}\\n\\n\"\n",
    "        f\"Question: {query}\\nAnswer:\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5cdf56",
   "metadata": {},
   "source": [
    "Step 10: Decode helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "992e2098",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dedupe_tokens(text: str) -> str:\n",
    "    toks = text.split()\n",
    "    out = [toks[0]] if toks else []\n",
    "    for tok in toks[1:]:\n",
    "        if tok != out[-1]:\n",
    "            out.append(tok)\n",
    "    return \" \".join(out)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a166da",
   "metadata": {},
   "source": [
    "Step 11: RAG answer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bb4c3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(query: str, conv: Conversation,\n",
    "           top_k: int = TOP_K) -> Tuple[str, List[Dict]]:\n",
    "    retrieved = retrieve(query, top_k)\n",
    "\n",
    "    # out-of-scope / ambiguous check\n",
    "    if (not retrieved) or (retrieved[0][\"distance\"] > DISTANCE_THRESHOLD):\n",
    "        response = (\n",
    "            \"I do not know. The knowledge base does not contain \"\n",
    "            \"information relevant to this question.\"\n",
    "        )\n",
    "        conv.add(query, response)\n",
    "        return response, []                 # ← return empty list instead of nothing\n",
    "\n",
    "    prompt = make_prompt(\n",
    "        query,\n",
    "        [r[\"text\"] for r in retrieved],\n",
    "        conv.format_history()\n",
    "    )\n",
    "\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    ).to(DEVICE)\n",
    "\n",
    "    out_ids = generator.generate(\n",
    "        **inputs,\n",
    "        max_length=220,\n",
    "        num_beams=4,\n",
    "        temperature=0.7,\n",
    "        no_repeat_ngram_size=3,\n",
    "        repetition_penalty=1.15\n",
    "    )\n",
    "\n",
    "    response = tokenizer.decode(out_ids[0], skip_special_tokens=True)\n",
    "    response = dedupe_tokens(response)\n",
    "    conv.add(query, response)\n",
    "    return response, retrieved              # ← always two objects\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8109e1b",
   "metadata": {},
   "source": [
    "Step 12: Demo query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5cc30c8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Suggest a spicy chicken item\n",
      "\n",
      "Answer:\n",
      "spicy deluxe mccrispya\n",
      "\n",
      "Retrieved context:\n",
      "- mcdonald s usa chicken fish sandwiches spicy deluxe mccrispya try mcdonald s spicy deluxe mccrispy chicken sandwichacrispy chicken with spicy pepper sauce order this spicy deluxe chicken sandwich in the app vegetarian vegan option spicy allergens information nutrition calculator related product mcriba mcriba spicy mccrispya spicy mccrispya deluxe mccrispya deluxe mccrispya 10 piece chicken mcnuggetsa 10 piece chicken mcnuggetsa important note at mcdonald s we take great care to serve quality great tasting menu items to our customers each and every time they visit our restaurants  (distance=0.807)\n",
      "\n",
      "\n",
      "- mcdonald s usa featured favorites spicy mccrispya mcdonaldatms spicy mccrispy chicken sandwich is made with southern style fried chicken spicy pepper sauce grab it at your nearest mcdonald s today vegetarian vegan option spicy allergens information nutrition calculator related product spicy deluxe mccrispya spicy deluxe mccrispya mccrispya mccrispya deluxe mccrispya deluxe mccrispya 10 piece chicken mcnuggetsa 10 piece chicken mcnuggetsa important note at mcdonald s we take great care to serve quality great tasting menu items to our customers each and every time they visit our restaurants  (distance=0.864)\n",
      "\n",
      "\n",
      "- mcdonald s usa featured favorites chicken mcnuggetsa mcdonald s chicken mcnuggetsa are all white meat chicken nuggets with no artificial preservatives try tender juicy chicken nuggets at mcdonald s near you vegetarian vegan option spicy allergens information nutrition calculator related product spicy deluxe mccrispya spicy deluxe mccrispya mccrispya mccrispya spicy mccrispya spicy mccrispya deluxe mccrispya deluxe mccrispya important note at mcdonald s we take great care to serve quality great tasting menu items to our customers each and every time they visit our restaurants  (distance=0.936)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    chat = Conversation()\n",
    "\n",
    "    user_query = \"Suggest a spicy chicken item\"\n",
    "    reply, ctx = answer(user_query, chat)\n",
    "\n",
    "    print(\"Query:\")\n",
    "    print(user_query)\n",
    "    print(\"\\nAnswer:\")\n",
    "    print(reply)\n",
    "    print(\"\\nRetrieved context:\")\n",
    "    for r in ctx:\n",
    "      print(f\"- {r['text']}  (distance={r['distance']:.3f})\")\n",
    "      print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bad16a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
